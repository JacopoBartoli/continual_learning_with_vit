{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23c9df2b-7108-48c7-9571-9e9e2cd604fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import ipdb\n",
    "from networks.vit_original import VisionTransformer as VT \n",
    "from networks.vit_original import _load_weights as LoadW\n",
    "\n",
    "from networks.ovit import VisionTransformer as oVT\n",
    "from networks.ovit import _load_weights as oLoadW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26fd2f46-2357-490b-9a7b-34818d1299f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/home/fpelosin/vit_facil/src/networks/pretrained_weights/augreg_Ti_16-i1k-300ep-lr_0.001-aug_light1-wd_0.1-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.01-res_224.npz'\n",
    "\n",
    "\n",
    "# Custom\n",
    "ovit = oVT(embed_dim=192, num_classes=0)\n",
    "oLoadW(model=ovit, checkpoint_path=filename)\n",
    "ovit.eval()\n",
    "\n",
    "\n",
    "# timm\n",
    "#vit = timm.create_model('vit_tiny_patch16_224', num_classes=0)\n",
    "#timm.models.load_checkpoint(vit, filename)\n",
    "#vit.eval()\n",
    "vit = VT(embed_dim=192, num_classes=0)\n",
    "LoadW(model=vit, checkpoint_path=filename)\n",
    "vit.eval()\n",
    "\n",
    "\n",
    "# timm\n",
    "timm_vit = timm.create_model('vit_tiny_patch16_224', num_classes=0)\n",
    "timm.models.load_checkpoint(timm_vit, filename)\n",
    "timm_vit.eval()\n",
    "\n",
    "\n",
    "inp = torch.rand(1,3,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0dcb128d-0f58-4b1a-9562-e257a2e73473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,2):\n",
    "    vit_chunk = torch.nn.Sequential(vit.patch_embed, vit.pos_drop, vit.blocks[:3])\n",
    "    ovit_chunk = torch.nn.Sequential(ovit.patch_embed, ovit.pos_drop, ovit.blocks[:3])\n",
    "    \n",
    "    #ovit_chunk = torch.nn.Sequential(ovit.patch_embed, ovit.pos_drop, ovit.blocks[:i][0].norm1, ovit.blocks[:i][0].attn.qkv, \n",
    "                                     #ovit.blocks[:i][0].attn.attn_drop, ovit.blocks[:i][0].attn.proj)\n",
    "\n",
    "\n",
    "    out_vit = vit_chunk(inp)\n",
    "    out_ovit = ovit_chunk(inp)\n",
    "\n",
    "    print((out_vit-out_ovit).sum())\n",
    "\n",
    "#out_vit, out_ovit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae92ab6d-132d-44f3-a92f-701777f1aed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): PatchEmbed(\n",
       "     (proj): Conv2d(3, 192, kernel_size=(16, 16), stride=(16, 16))\n",
       "     (norm): Identity()\n",
       "   )\n",
       "   (1): Dropout(p=0.0, inplace=False)\n",
       "   (2): Sequential(\n",
       "     (0): Block(\n",
       "       (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "       (attn): Attention(\n",
       "         (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "         (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "         (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "       (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "       (mlp): Mlp(\n",
       "         (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "         (act): GELU()\n",
       "         (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (1): Block(\n",
       "       (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "       (attn): Attention(\n",
       "         (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "         (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "         (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "       (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "       (mlp): Mlp(\n",
       "         (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "         (act): GELU()\n",
       "         (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (2): Block(\n",
       "       (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "       (attn): Attention(\n",
       "         (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "         (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "         (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "       (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "       (mlp): Mlp(\n",
       "         (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "         (act): GELU()\n",
       "         (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): PatchEmbed(\n",
       "     (proj): Conv2d(3, 192, kernel_size=(16, 16), stride=(16, 16))\n",
       "     (norm): Identity()\n",
       "   )\n",
       "   (1): Dropout(p=0.0, inplace=False)\n",
       "   (2): Sequential(\n",
       "     (0): Block(\n",
       "       (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "       (attn): Attention(\n",
       "         (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "         (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "         (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "       (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "       (mlp): Mlp(\n",
       "         (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "         (act): GELU()\n",
       "         (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (1): Block(\n",
       "       (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "       (attn): Attention(\n",
       "         (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "         (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "         (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "       (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "       (mlp): Mlp(\n",
       "         (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "         (act): GELU()\n",
       "         (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (2): Block(\n",
       "       (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "       (attn): Attention(\n",
       "         (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "         (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "         (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "       (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "       (mlp): Mlp(\n",
       "         (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "         (act): GELU()\n",
       "         (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_chunk, ovit_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3d835a1-0131-41f3-b3d9-212d25ea125d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 196, 576]), torch.Size([1, 196, 576]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_vit.shape, out_ovit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27ba4fd6-e0cc-4697-a0fa-ea4f19635a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "networks.vit_original.VisionTransformer"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ovit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a1dcb24-600b-48b6-9ea4-682f300d1389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 192, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "  (pre_logits): Identity()\n",
       "  (head): Identity()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a198991-97b3-451d-a2c2-bf041825cfdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
